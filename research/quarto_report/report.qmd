\begin{center}
{\Large \textbf{Deploying Real Time Object Detection Inference Systems}} \\
\vspace{1em}
Yves Kreimerman, 2025
\end{center}

**Abstract.** Computer vision is a field in machine learning that aims to understand a give picture, identify what's going on and classify those into classes(patterns) it understands. There are couple of main fields in the computer vision world, those being:

1. **Classification** - The model classifies a whole picture into classes. It is possible for the model to classify the picture as multiple classes(Multi-Label Classification), or one class, being the most dominant(Multi-Class Classification) \newline
2. **Object Detection** - The model omits a series of boxes around various object it identifies(based on the data it was trained), pointing to the coordinates where the object is found on the picture. \newline
3. **Semantic Segmentation** - The model identifies pixels as part of a class, but does not distinct between different objects sharing the same class \newline
4. **Instance Segmentation**- The model identifies pixels as part of a class, and has the distinction between objects. it is able to distinct two objects from the same class that are nearby.

# 1. Introduction
Live streaming video is a broad subject, of producing a live video feed which is constantly broadcasted from various sources, with consumers watching on the other end. Live streaming is usually split into couple of main categories, the main ones being:

```{=latex}
\begin{table}[h!]
\centering
\begin{tabular}{|l|c|l|}
\hline
\textbf{Type} & \textbf{Delay Range (Seconds)} & \textbf{Use} \\
\hline
WebRTC & 0.5 - 2 & Real Time (video calls, surveillance) \\
\hline
Broadcast Live & 2 - 5 & TV (News, Sports) \\
\hline
RTMP/HLS & 5 - 30+ & Live Media (Youtube, Twitch) \\
\hline
\end{tabular}
\caption{Main categories of live streaming}
\end{table}
```

Having Machine Learning fit model into the chain of live streaming can be difficult, as it requires us to fit under very slim time constraints. \newline
With Real Time being our main subject, we will go over the constraints we should take into count, and how they project on our system design: 

1. **Source Capture & Extraction of raw frame** - Getting raw frames from source, before any manipulations - \underline{30ms} \newline
2. **Machine Learning Inference** - Processing, model inference, postprocessing \newline
3. **Video encoding & Processing** - Processing frames into actual video, encoding to various formats(e.g. H264) - \underline{20ms} \newline
4. **Network Transport** - Transporting the processed video to consumer(Over LAN/WAN) - \underline{100ms-150ms} \newline
5. **Consumer Decoding & Display** - Displaying the video to the end consumer via streaming platform - \underline{100ms-130ms}

The numbers shown are for an ideal scenario, and in reality numbers are much higher. That requires us to fit under very low constraints, ideally around **15ms-75ms**, depending on video frame rate and network throughput.
{{< pagebreak >}}

# 3. Methodology
Having tight time constraints to take into consideration, we would have to design a low-latency, high throughput system, that can serve as many video sources as possible, while utilizing the most from the given resources.

## 3.1 Model Precision
With the goal of minimizing latency of inferance, and maximizing processing throughput, we need a way to optimize the given ML models and squeeze the best preformance out of those. \newline
By default, machine learning models use FP32(Floating point 32) datatypes for weights and inputs/outputs by default, allowing higher precision for training, therefore maximizing accuracy. When running inference on the same models, we don't necessarily need all that precision and can "compromise" on lower floating points, i.e. FP16. FP16 should give us much better preformance, while almost not compromising on accuracy. \newline
We first want to test all model versions for accuracy, determine how lossy is the conversion of floating points and is compromising on floating points even worth it. \newline
We will do so with a pre-made evaluation script, while models are evaluated on MS-COCO Val 2017 dataset, for consistency purposes(all models are trained on the same data too). \newline
The goal is to demonstrate how one model compares to another, so the actual performance of the model(how well it performs on the data) is negligible.

:::{.center}
![mAP (under different IOUs)](../images/map_comparison.png){width=270pt}

![Precision - Confidence Curve](../images/precision_confidence_curve.png){width=270pt}

![Recall - Confidence Curve](../images/recall_confidence_curve.png){width=270pt}

![F1 Score - Confidence Curve](../images/f1_score_confidence_curve.png){width=270pt}

![Precision - Recall Curve](../images/precision_recall_curve.png){width=270pt}
:::

While it may not be visible right away, we can see that FP16 and FP32 results for the same kind of model are overlapping in all curves. This means that they both reach identical results(with minor changes after the 4th floating digit). \newline
With that said, **FP16 models will be our choice of deployment** as they allow us to have the same inference accuracy while significantly lowering inference time(higher throughput).

{{< pagebreak >}}

## 3.2 Architecture overview
:::{.center}
![Architecture for a real time video inference system](../images/architecture.png){width=320pt}
:::
Having our model pushed to it's limit is really great, but we also need a steady system to back it up. We must build a strong, low latency inference system, that doesn't create an overhead for pre-processing video input or post-processing model output, and allows us to serve inference results at near model time. for that we have two main options:

* **Python** - Has a very rich ML/processing tools such as pytorch, numpy, openCV, numba and much more, allowing us to run code in times close to C language. Having said that, it has many downsides, which we should take in mind:
    - Poor optimization - Python is not a low level programming language, therefore has many overhead components that hurt runtime(garbage collector, datatypes) and prevent us from getting instant response.
    - Poor Multi-Threading - Running multiple threads(for multiple video streams for example) is very limited, as Python's GIL(Global Interpreter Lock) prevents us to run more than one python bytecode at a given time. Even with multithread packages(i.g. threading), will have to wait in queue for GIL to finish - not ideal for real time scenarios.

* **Rust** - Has a growing set of ML tools, such as openCV, ndarray(Numpy-like) and more, providing sufficient tools in our case. Rust has multiple upsides in case of real time inference:
    - C-like performance - Rust is very efficient, having no overhead components(No garbage collector) and other datatypes that can hurt runtime, rust allows us to write code in high level syntax with low level performance. Great for achieving real-time computations.
    - Real multi-threading - Rust allows us run our program in real parallel, on multiple cores at a time natively. This allows us to serve multiple streams seperately without them depending on each other to finish running.

    With that said, rust has a rather steep learning curve, and it takes time for an average programmer to be able to write production grade code.

With that said, **Rust will be our language of choice**, having its capabilities overcome Python's, and with the idea of having our system be stable, fast and reliable over time.