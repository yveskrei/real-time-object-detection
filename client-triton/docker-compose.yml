services:
  triton_server:
    image: nvcr.io/nvidia/tritonserver:23.08-py3
    container_name: triton_server
    restart: unless-stopped

    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all

    ports:
      - "8000:8000"
      - "8001:8001"
      - "8002:8002"

    volumes:
      - ./triton_models:/models:rw
      - ./triton_logs:/logs

    command: >
      tritonserver
      --model-repository=/models
      --model-control-mode=explicit
      --allow-http=true
      --allow-grpc=true
      --allow-metrics=true
      --log-verbose=1
      --log-file=/logs/triton.log
      --exit-on-error=false
      --strict-model-config=false
      --backend-config=python,shm-default-byte-size=1048576

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/v2/health/ready"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
  
  minio_triton:
    image: minio/minio:RELEASE.2025-04-22T22-12-26Z
    container_name: minio_triton
    ports:
      - "4000:9000"
      - "4001:9001"
    environment:
      MINIO_ROOT_USER: minio
      MINIO_ROOT_PASSWORD: minio123
    command: server /data --console-address ":9001"
    volumes:
      - minio_triton_data:/data
  
volumes:
  triton_data:
  minio_triton_data: